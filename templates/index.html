<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>语音降调助听器</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: #f5f7fa; min-height: 100vh; padding: 20px; }
        .container { background: white; border-radius: 16px; padding: 30px 20px; max-width: 640px; width: 100%; margin: 0 auto; box-shadow: 0 2px 8px rgba(0,0,0,0.08); }
        h1 { color: #2c3e50; margin-bottom: 8px; text-align: center; font-size: 28px; font-weight: 600; }
        .subtitle { color: #7f8c8d; text-align: center; margin-bottom: 30px; font-size: 18px; }
        .section { margin-bottom: 24px; }
        .section-title { color: #2c3e50; font-size: 20px; margin-bottom: 14px; font-weight: 600; }
        label { display: block; color: #2c3e50; margin-bottom: 10px; font-size: 18px; }
        input[type="range"] { width: 100%; margin: 10px 0 8px 0; }
        .value-display { text-align: center; color: #2980b9; font-weight: 700; font-size: 22px; margin-top: 4px; }
        .record-button-container { display: flex; justify-content: center; margin: 12px 0 10px; }
        .btn-circle { width: 140px; height: 140px; border-radius: 50%; background: linear-gradient(135deg, #ff6b6b, #ff4757); color: white; border: none; font-size: 18px; font-weight: 600; display: flex; flex-direction: column; align-items: center; justify-content: center; box-shadow: 0 10px 25px rgba(255, 99, 132, 0.3); cursor: pointer; transition: transform 0.2s, box-shadow 0.2s; }
        .btn-circle .icon { font-size: 40px; margin-bottom: 6px; }
        .btn-circle:active { transform: scale(0.96); box-shadow: 0 6px 15px rgba(255, 99, 132, 0.25); }
        .btn:disabled { background: #bdc3c7; cursor: not-allowed; box-shadow: none; }
        .status { text-align: center; padding: 16px; border-radius: 12px; margin: 16px 0; display: none; font-size: 18px; font-weight: 500; }
        .status.success { background: #d4edda; color: #155724; display: block; }
        .status.error { background: #f8d7da; color: #721c24; display: block; }
        .status.processing { background: #d1ecf1; color: #0c5460; display: block; }
        .status.info { background: #cce5ff; color: #004085; display: block; }
        audio { width: 100%; margin-top: 12px; border-radius: 8px; height: 54px; }
        @media (max-width: 768px) { body { padding: 10px; } .container { padding: 22px 14px; } h1 { font-size: 24px; } .subtitle { font-size: 16px; } .section-title { font-size: 18px; } label { font-size: 16px; } .value-display { font-size: 20px; } .btn-circle { width: 120px; height: 120px; font-size: 16px; } .btn-circle .icon { font-size: 32px; } }
    </style>
</head>
<body>
    <div class="container">
        <h1>语音降调助听器</h1>
        <p class="subtitle">帮助老年人更清晰地听到对话 <span style="font-size:14px;color:#666;">（版本 {{ version }}）</span></p>

        <div class="section">
            <div class="section-title">降调调整（相对降低）</div>
            <div class="control-group">
                <label for="semitones">降低半音数: <span id="semitone-value">-5.0</span></label>
                <input type="range" id="semitones" min="-12" max="0" step="0.5" value="-5">
                <div class="value-display" id="pitch-description">中度降低（适合女声）</div>
            </div>
        </div>

        <div class="section" id="recordSection">
            <div class="section-title">从麦克风录音（单按钮循环录制）</div>
            <div class="record-button-container">
                <button id="recordBtn" class="btn-circle">
                    <span class="icon">⏺</span>
                    <span id="recordLabel">开始录音</span>
                </button>
            </div>
        </div>

        <div id="status" class="status"></div>

        <div id="outputSection" class="section" style="display: none;">
            <div class="section-title">降调后的音频（自动播放）</div>
            <audio id="outputAudio" controls autoplay style="width: 100%; margin-bottom: 20px;"></audio>
            <div class="section-title">速度调整（播放时实时调整）</div>
            <div class="control-group">
                <label>选择播放速度:</label>
                <div style="margin-top: 10px;">
                    <label style="display: inline-block; margin-right: 20px; cursor: pointer;">
                        <input type="radio" name="speed" value="0.9" checked style="margin-right: 5px;">正常速度 (0.9x)
                    </label>
                    <label style="display: inline-block; margin-right: 20px; cursor: pointer;">
                        <input type="radio" name="speed" value="0.7" style="margin-right: 5px;">较慢 (0.7x)
                    </label>
                    <label style="display: inline-block; cursor: pointer;">
                        <input type="radio" name="speed" value="0.5" style="margin-right: 5px;">很慢 (0.5x)
                    </label>
                </div>
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let currentAudioBlob = null;
        let recordingTimeout = null;
        const MAX_RECORDING_SECONDS = 30;
        const MAX_FILE_SIZE_MB = 1;

        const recordBtn = document.getElementById('recordBtn');
        const recordLabel = document.getElementById('recordLabel');
        const semitonesSlider = document.getElementById('semitones');
        const semitoneValue = document.getElementById('semitone-value');
        const pitchDescription = document.getElementById('pitch-description');
        const outputAudio = document.getElementById('outputAudio');
        const status = document.getElementById('status');
        const recordSection = document.getElementById('recordSection');
        const outputSection = document.getElementById('outputSection');

        function stopPlayback() {
            if (!outputAudio.paused) {
                outputAudio.pause();
            }
            if (outputAudio.src) {
                outputAudio.currentTime = 0;
            }
        }

        semitonesSlider.addEventListener('input', (e) => {
            const value = parseFloat(e.target.value);
            semitoneValue.textContent = value.toFixed(1);
            if (value === 0) pitchDescription.textContent = '不降调（原声）';
            else if (value > -3) pitchDescription.textContent = '轻微降低（适合略高的声音）';
            else if (value >= -5) pitchDescription.textContent = '轻度降低（适合女声）';
            else if (value >= -8) pitchDescription.textContent = '中度降低（适合高音女声）';
            else pitchDescription.textContent = '重度降低（适合特别尖的声音）';
        });

        document.querySelectorAll('input[name="speed"]').forEach(radio => {
            radio.addEventListener('change', (e) => {
                const selectedSpeed = parseFloat(e.target.value);
                if (outputAudio.src) {
                    // Apply duration compensation when changing speed
                    const semitones = parseFloat(semitonesSlider.value);
                    const pitchRatio = Math.pow(2, semitones / 12.0);
                    const durationCompensation = 1.0 / pitchRatio;
                    outputAudio.playbackRate = selectedSpeed * durationCompensation;
                }
            });
        });

        // Note: With UptimeRobot monitoring, the container stays awake 24/7.
        // Server pre-loads librosa at startup, so no client-side warmup needed.
        console.log('✅ Page loaded - service kept alive by external monitoring');

        recordBtn.addEventListener('click', async () => {
            console.log('🔴 Record button clicked');
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                console.log('⏹️ Stopping recording...');
                if (recordingTimeout) {
                    clearTimeout(recordingTimeout);
                    recordingTimeout = null;
                }
                mediaRecorder.stop();
                return;
            }
            stopPlayback();
            try {
                console.log('🎤 Requesting microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                console.log('✅ Microphone access granted');
                let options = { mimeType: 'audio/wav' };
                if (!MediaRecorder.isTypeSupported('audio/wav')) options = { mimeType: 'audio/webm' };
                console.log('🎙️ Using MIME type:', options.mimeType);
                mediaRecorder = new MediaRecorder(stream, options);
                audioChunks = [];
                mediaRecorder.addEventListener('dataavailable', (event) => { 
                    console.log('📦 Audio data chunk received:', event.data.size, 'bytes');
                    audioChunks.push(event.data); 
                });
                mediaRecorder.addEventListener('stop', async () => {
                    console.log('⏹️ Recording stopped, total chunks:', audioChunks.length);
                    const mimeType = mediaRecorder.mimeType;
                    let blob = new Blob(audioChunks, { type: mimeType });
                    console.log('📊 Created blob:', blob.size, 'bytes, type:', blob.type);
                    if (mimeType.includes('webm')) {
                        console.log('🔄 Converting webm to wav...');
                        try {
                            blob = await convertWebmToWav(blob);
                            console.log('✅ Conversion complete:', blob.size, 'bytes');
                        } catch (e) {
                            console.error('❌ Conversion failed:', e);
                            showStatus('error', '音频转换失败: ' + e.message);
                            return;
                        }
                    }
                    currentAudioBlob = blob;
                    console.log('✅ Audio blob ready:', currentAudioBlob.size, 'bytes');
                    
                    // Check file size before uploading
                    const sizeMB = currentAudioBlob.size / (1024 * 1024);
                    console.log('📏 File size:', sizeMB.toFixed(2), 'MB');
                    if (sizeMB > MAX_FILE_SIZE_MB) {
                        console.error('❌ File too large:', sizeMB.toFixed(2), 'MB (max:', MAX_FILE_SIZE_MB, 'MB)');
                        showStatus('error', `录音文件过大 (${sizeMB.toFixed(1)}MB)，请录制更短的音频（少于${MAX_RECORDING_SECONDS}秒）`);
                        stream.getTracks().forEach(track => track.stop());
                        setState('idle');
                        return;
                    }
                    
                    stream.getTracks().forEach(track => {
                        console.log('🛑 Stopping track:', track.kind);
                        track.stop();
                    });
                    console.log('🚀 Calling processAudio()...');
                    await processAudio();
                });
                mediaRecorder.start();
                console.log('▶️ Recording started');
                setState('recording');
                showStatus('info', `正在录音（最长${MAX_RECORDING_SECONDS}秒），再次点击即可停止并转化`);
                
                // Auto-stop after MAX_RECORDING_SECONDS
                recordingTimeout = setTimeout(() => {
                    console.log(`⏱️ Auto-stopping recording after ${MAX_RECORDING_SECONDS} seconds`);
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                    }
                }, MAX_RECORDING_SECONDS * 1000);
            } catch (err) {
                console.error('❌ Microphone error:', err);
                showStatus('error', '无法访问麦克风: ' + err.message);
            }
        });

        async function wakeUpService() {
            console.log('🔥 Waking up service...');
            const wakeStart = performance.now();
            try {
                // Simple fetch without abort - if it takes too long, the main request will handle it
                await fetch('/', { method: 'HEAD' });
                
                const wakeTime = ((performance.now() - wakeStart) / 1000).toFixed(2);
                console.log(`✅ Service awake in ${wakeTime}s`);
                return true;
            } catch (error) {
                const wakeTime = ((performance.now() - wakeStart) / 1000).toFixed(2);
                console.log(`⚠️ Wake-up attempt took ${wakeTime}s:`, error.message);
                return false; // Continue anyway, might still work
            }
        }

        async function processAudio() {
            if (!currentAudioBlob) {
                console.error('❌ No audio blob to process');
                showStatus('error', '没有可处理的录音');
                return;
            }
            console.log('🚀 Starting processAudio()');
            console.log('📊 Blob size:', currentAudioBlob.size, 'bytes');
            console.log('📊 Blob type:', currentAudioBlob.type);
            console.log('🎚️ Semitones:', semitonesSlider.value);
            
            // Wake up the service first if it's asleep (handles cold starts)
            await wakeUpService();
            
            setState('processing');
            showStatus('processing', '正在转化并降低声调...');
            const formData = new FormData();
            formData.append('audio', currentAudioBlob, 'recording.wav');
            formData.append('semitones', semitonesSlider.value);
            
            const requestStartTime = performance.now();
            const startTime = new Date().toLocaleTimeString('en-US', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit' });
            console.log(`📤 [${startTime}] Sending POST request to /process`);
            try {
                const controller = new AbortController();
                const timeoutId = setTimeout(() => {
                    const abortTime = new Date().toLocaleTimeString('en-US', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit' });
                    console.log(`⏰ [${abortTime}] 30-second timeout reached, aborting request`);
                    controller.abort();
                }, 30000); // 30 second timeout
                const response = await fetch('/process', { 
                    method: 'POST', 
                    body: formData,
                    signal: controller.signal
                });
                clearTimeout(timeoutId);
                const requestEndTime = performance.now();
                const requestDuration = ((requestEndTime - requestStartTime) / 1000).toFixed(2);
                console.log('📥 Response status:', response.status, response.statusText);
                console.log('⏱️ Total request time:', requestDuration, 'seconds');
                
                if (!response.ok) {
                    const contentType = response.headers.get('content-type');
                    if (contentType && contentType.includes('application/json')) {
                        const error = await response.json();
                        console.error('❌ Server error (JSON):', error);
                        throw new Error(error.error || 'Processing failed');
                    } else {
                        const text = await response.text();
                        console.error('❌ Server error (text):', text);
                        throw new Error('Server error: ' + text);
                    }
                }
                
                const blob = await response.blob();
                console.log('✅ Received processed audio blob:', blob.size, 'bytes');
                const url = URL.createObjectURL(blob);
                outputAudio.src = url;
                
                // Calculate playback rate to compensate for duration change from resampling
                // When pitch is lowered, audio becomes longer, so we speed up playback
                const semitones = parseFloat(semitonesSlider.value);
                const pitchRatio = Math.pow(2, semitones / 12.0);
                const durationCompensation = 1.0 / pitchRatio; // Inverse to restore original duration
                
                const selectedSpeed = parseFloat(document.querySelector('input[name="speed"]:checked').value);
                const finalPlaybackRate = selectedSpeed * durationCompensation;
                outputAudio.playbackRate = finalPlaybackRate;
                
                console.log(`🎵 Semitones: ${semitones}, Pitch ratio: ${pitchRatio.toFixed(4)}, Duration compensation: ${durationCompensation.toFixed(4)}, Final playback rate: ${finalPlaybackRate.toFixed(4)}`);
                
                setState('processed');
                console.log('🎵 Attempting to play audio...');
                try {
                    await outputAudio.play();
                    console.log('✅ Audio playing');
                    showStatus('success', '降调完成，已自动播放处理后的音频');
                } catch (playErr) {
                    console.warn('⚠️ Autoplay failed:', playErr);
                    showStatus('success', '降调完成，如未自动播放请手动点击播放');
                }
            } catch (err) {
                const errorTime = new Date().toLocaleTimeString('en-US', { hour12: false, hour: '2-digit', minute: '2-digit', second: '2-digit' });
                const elapsedTime = ((performance.now() - requestStartTime) / 1000).toFixed(2);
                console.error(`❌ [${errorTime}] Error in processAudio after ${elapsedTime}s:`, err);
                if (err.name === 'AbortError') {
                    showStatus('error', `处理超时(${elapsedTime}秒) - 服务可能正在启动，请稍后重试`);
                } else if (err.message && (err.message.includes('504') || err.message.includes('502'))) {
                    showStatus('error', '服务正在启动中，请等待30秒后重试');
                } else {
                    showStatus('error', '处理失败: ' + (err.message || err));
                }
                setState('idle');
            }
        }

        function setState(state) {
            if (state === 'idle') {
                recordSection.style.display = 'block';
                recordBtn.disabled = false;
                recordLabel.textContent = '开始录音';
                semitonesSlider.disabled = false;
                outputSection.style.display = outputAudio.src ? 'block' : 'none';
                outputAudio.src = '';
                status.className = 'status';
                status.textContent = '';
                currentAudioBlob = null;
            } else if (state === 'recording') {
                stopPlayback();
                recordSection.style.display = 'block';
                recordBtn.disabled = false;
                recordLabel.textContent = '停止并转化';
                semitonesSlider.disabled = true;
                outputSection.style.display = 'none';
            } else if (state === 'processing') {
                stopPlayback();
                recordBtn.disabled = true;
                recordLabel.textContent = '正在转化...';
                semitonesSlider.disabled = true;
            } else if (state === 'processed') {
                recordBtn.disabled = false;
                recordLabel.textContent = '再次录音';
                semitonesSlider.disabled = false;
                outputSection.style.display = 'block';
            }
        }

        async function convertWebmToWav(webmBlob) {
            // Use 16kHz sample rate to match server processing and reduce file size
            const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            const arrayBuffer = await webmBlob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Convert to mono if stereo (further reduces size)
            let monoBuffer = audioBuffer;
            if (audioBuffer.numberOfChannels > 1) {
                const offlineContext = new OfflineAudioContext(1, audioBuffer.length, 16000);
                const source = offlineContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(offlineContext.destination);
                source.start(0);
                monoBuffer = await offlineContext.startRendering();
            }
            
            const wavBuffer = audioBufferToWav(monoBuffer);
            return new Blob([wavBuffer], { type: 'audio/wav' });
        }

        function audioBufferToWav(buffer) {
            const length = buffer.length * buffer.numberOfChannels * 2 + 44;
            const arrayBuffer = new ArrayBuffer(length);
            const view = new DataView(arrayBuffer);
            const channels = [];
            let offset = 0;
            let pos = 0;
            setUint32(0x46464952);
            setUint32(length - 8);
            setUint32(0x45564157);
            setUint32(0x20746d66);
            setUint32(16);
            setUint16(1);
            setUint16(buffer.numberOfChannels);
            setUint32(buffer.sampleRate);
            setUint32(buffer.sampleRate * 2 * buffer.numberOfChannels);
            setUint16(buffer.numberOfChannels * 2);
            setUint16(16);
            setUint32(0x61746164);
            setUint32(length - pos - 4);
            for (let i = 0; i < buffer.numberOfChannels; i++) channels.push(buffer.getChannelData(i));
            while (pos < length - 44) {
                for (let i = 0; i < buffer.numberOfChannels; i++) {
                    let sample = Math.max(-1, Math.min(1, channels[i][offset]));
                    sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    view.setInt16(pos, sample, true);
                    pos += 2;
                }
                offset++;
            }
            return arrayBuffer;
            function setUint16(data) { view.setUint16(pos, data, true); pos += 2; }
            function setUint32(data) { view.setUint32(pos, data, true); pos += 4; }
        }

        setState('idle');

        function showStatus(type, message) {
            status.className = 'status ' + type;
            status.textContent = message;
        }
    </script>
</body>
</html>
